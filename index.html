<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=".">
  <meta name="keywords" content="DeCoRe, hallucination mitigation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucination</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./docs/static/css/bulma.min.css">
  <link rel="stylesheet" href="./docs/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./docs/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./docs/static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./docs/static/css/index.css">
  <link rel="icon" href="./docs/static/images/az_logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./docs/static/js/fontawesome.all.min.js"></script>
  <script src="./docs/static/js/bulma-carousel.min.js"></script>
  <script src="./docs/static/js/bulma-slider.min.js"></script>
  <script src="./docs/static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucination</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://aryopg.github.io">Aryo Pradipta Gema</a><sup>Q, K</sup>,</span>
            <span class="author-block">
              <a href="https://chenjin.netlify.app/">Chen Jin</a><sup>K</sup>,</span>
            <span class="author-block">
              <a href="https://uk.linkedin.com/in/ahmed-abdulaal-5b8b6a295">Ahmed Abdulaal</a><sup>K, V</sup>,
            </span>
            <span class="author-block">
              <a href="https://tomdiethe.com/">Tom Diethe</a><sup>K</sup>,
            </span>
            <span class="author-block">
              <a href="https://uk.linkedin.com/in/philteare">Philip Teare</a><sup>K</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.ed.ac.uk/profile/dr-beatrice-alex">Beatrice Alex</a><sup>Q</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.neuralnoise.com/">Pasquale Minervini</a><sup>Q, A</sup>,
            </span>
            <span class="author-block">
              <a href="https://uk.linkedin.com/in/amrutha-saseendran">Amrutha Saseendran</a><sup>K</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>Q</sup>University of Edinburgh, United Kingdom</span>
            <span class="author-block"><sup>K</sup>Centre for AI, Data Science & Artificial Intelligence, R&D, AstraZeneca, United Kingdom</span>
            <span class="author-block"><sup>V</sup>University College London, United Kingdom</span>
            <span class="author-block"><sup>A</sup>Miniml.AI, United Kingdom</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.18860"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.18860"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/aryopg/decore"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" src="docs/assets/decore_entropy_final.gif" alt="DeCoRe reduces hallucinations in LLMs" height="100%" />
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">DeCoRe</span> reduces hallucinations in LLMs by contrasting outputs from the base model and a variant without retrieval heads, using predictive entropy to dynamically reject unfaithful responses
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) often hallucinate, producing unfaithful or factually incorrect outputs by misrepresenting the provided context or incorrectly recalling internal knowledge.
          </p>
          <p>
            Recent studies have identified specific attention heads within the Transformer architecture, known as <i>retrieval heads</i>, responsible for extracting relevant contextual information.
            We hypothesise that masking these retrieval heads can induce hallucinations and that contrasting the outputs of the base LLM and the masked LLM can reduce hallucinations.
          </p>
          <p>
            To this end, we propose <b>De</b>coding by <b>Co</b>ntrasting <b>Re</b>trieval Heads (<span class="dnerf"><b>DeCoRe</b></span>), a novel training-free decoding strategy that amplifies information found in the context and model parameters.
            DeCoRe mitigates potentially hallucinated responses by dynamically contrasting the outputs of the base LLM and the masked LLM, using conditional entropy as a guide.
          </p>
          <p>
            Our extensive experiments confirm that DeCoRe significantly improves performance on tasks requiring high contextual faithfulness, such as summarisation (XSum by 18.6%), instruction following (MemoTrap by 10.9%), and open-book question answering (NQ-Open by 2.4% and NQ-Swap by 5.5%)
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
    <div class="container is-max-desktop content">
        <div class="content">
        <h2 class="title">Masking Retrieval Heads Induces Hallucination</h2>
        <p>
            We observe that the masking retrieval heads produces hallucinated responses, as shown in the example below.
        </p>
        <div class="columns is-centered">
            <img src="./docs/assets/hallu_example.png" alt="Masking retrieval heads induces hallucination" height="100%" />
        </div>
        <p>
            The base model retrieves the correct answer from the substituted context, while the masked model provides a seemingly plausible, yet incorrect answer (neither the substituted nor the original answer)
        </p>
    </div>
    <div class="container is-max-desktop content">
        <div class="content">
        <h2 class="title">Dynamic Contrastive Decoding</h2>
        <p>
            Base model can be uncertain of its own prediction.
            Conditional entropy provides a natural way to quantify the uncertainty of the base modelâ€™s predictions.
        </p>
        <div class="columns is-centered">
            <img src="./docs/assets/conditional_entropy.png" alt="Conditional entropy to control contrastive decoding" height="100%"/>
        </div>
        <p>
            <span class="dnerf">DeCoRe</span> incorporates conditional entropy into the contrastive decoding process to dynamically adjust the strength of the penalty based on the conditional entropy of the base model.
        </p>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop content">
        <div class="content">
        <h2 class="title">Results and Analyses</h2>
        <p>
            <span class="dnerf">DeCoRe</span> significantly improves performance in tasks requiring contextual faithfulness. 
        </p>
        <br>
        <div class="columns is-centered">
            <img src="./docs/assets/results_faithfulness.png" alt="" height="100%" />
        </div>
        <br>
        <div class="columns is-centered">
            <img src="./docs/assets/results_factuality.png" alt="" height="100%" />
        </div>
        <br>
        <div class="columns is-centered">
            <img src="./docs/assets/results_cot.png" alt="" height="100%" />
        </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{gema2024decore,
  title={DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations}, 
  author={Aryo Pradipta Gema and Chen Jin and Ahmed Abdulaal and Tom Diethe and Philip Teare and Beatrice Alex and Pasquale Minervini and Amrutha Saseendran},
  year={2024},
  eprint={2410.18860},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.18860}, 
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>